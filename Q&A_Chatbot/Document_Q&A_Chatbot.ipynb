{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a76658-edaf-4519-a794-0d0573734d68",
   "metadata": {},
   "source": [
    "# Document Q&A Chatbot -- Langchain + GROQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0d49ccd-4650-4340-8779-f7b733e397aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv pinecone-client sentence-transformers langchain langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db13fa1a-75d7-4afb-a015-1717f8879771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Pinecone as LangPinecone\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import pdfplumber\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "737f16c2-1447-4d1b-99b8-fa1157f130c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47477194-dcfd-427b-a1d3-88ffcf2b3143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "# Define your index\n",
    "index_name = \"doc-qa-index\"\n",
    "\n",
    "# Check if index exists, if not create\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # all-MiniLM-L6-v2 has 384 dimensions\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e330f7-02f0-43a6-ae17-c7a381a5a3b7",
   "metadata": {},
   "source": [
    "## PDF Loader + Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8332f9e7-038e-41e3-93a2-2762ea53d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and chunk PDF\n",
    "def load_and_split_pdf(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        text = \"\\n\".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    return splitter.create_documents([text])\n",
    "\n",
    "# Load PDF\n",
    "docs = load_and_split_pdf(\"ICMLA_329_Final.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb63736-c2d6-43b6-a0d0-b41e7a0eaf09",
   "metadata": {},
   "source": [
    "## Embed and Store in Pinecone or FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5f23023-0472-4580-b603-3e3027a9a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Upload to Pinecone\n",
    "vectorstore = LangPinecone.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_model,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487ce71-d2d2-4f6d-a0b9-388eee824d38",
   "metadata": {},
   "source": [
    "## Ask Questions Using Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78cc46c7-c6ec-4596-9d82-f6143016ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Groq LLM\n",
    "llm = ChatGroq(api_key=groq_api_key, model_name=\"llama3-8b-8192\", temperature=0)\n",
    "\n",
    "# Build the RAG chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "969f7e8b-a8a4-4009-a96e-00674e3855b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      " The key findings in the document are:\n",
      "\n",
      "1. The deep learning-based enhancement model is capable of producing diagnostically valuable results, as confirmed by the example [24, 27].\n",
      "2. The application of post-processing techniques such as sharpening, gamma correction, adjusting illumination, denoising, and white balancing can significantly enhance image clarity.\n",
      "3. These post-processing techniques can improve contrast, fix uneven lighting, and reduce noise, making the images easier to interpret accurately, especially in clinical settings where precision matters.\n",
      "4. The hybrid strategy of combining deep learning-based enhancement with post-processing techniques provides a good middle ground, balancing clarity, resolution, and adaptability, making it suitable for practical medical imaging applications.\n",
      "\n",
      "Overall, the key findings suggest that the combination of deep learning-based enhancement and post-processing techniques can improve image quality and make it more suitable for medical diagnosis.\n"
     ]
    }
   ],
   "source": [
    "# Sample query\n",
    "query = \"What are the key findings in the document?\"\n",
    "result = qa_chain.invoke(query)\n",
    "\n",
    "# Display answer\n",
    "print(\"\\nAnswer:\\n\", result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c909b0-8b99-4f8f-80e2-789f991656f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
