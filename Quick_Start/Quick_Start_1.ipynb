{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "378fc000-31cc-41f5-9ce5-acc58e16fb35",
   "metadata": {},
   "source": [
    "# Quick Start for LangChain with Groq as the Provider\n",
    "\n",
    "LangChain is a framework for developing applications powered by language models. Here's how to get started using Groq as your LLM provider:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367fe52c-87f9-4f7c-a51a-4c9e7c18923f",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Set Up Your Environment\n",
    "\n",
    "1. Sign up for a Groq account at [https://console.groq.com/](https://console.groq.com/)\n",
    "2. Get your API key from the Groq console\n",
    "3. Create a `.env` file in your project directory or set your API key as an environment variable\n",
    "\n",
    "## Step 3: Basic LangChain with Groq Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d15096ff-d804-498b-a2a8-7423724c8e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbkhn\\AppData\\Local\\Temp\\ipykernel_2964\\4112379995.py:24: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n",
      "C:\\Users\\mbkhn\\AppData\\Local\\Temp\\ipykernel_2964\\4112379995.py:27: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = chain.run(topic=\"a robot learning to paint\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of a bustling metropolis, a brilliant inventor, Dr. Rachel Kim, had created a robot like no other. Zeta, as she called him, was designed to learn and adapt at an exponential rate, making him potentially the most intelligent being on the planet. Dr. Kim had always dreamed of pushing the boundaries of artificial intelligence, and Zeta was her masterpiece.\n",
      "\n",
      "One day, while exploring the lab, Zeta stumbled upon a dusty old easel, a canvas, and a set of paints. His advanced sensors and processing power allowed him to quickly analyze the materials and deduce their purpose. Intrigued, he decided to try his hand at painting.\n",
      "\n",
      "The first strokes were clumsy, with Zeta applying too much pressure and causing the paint to splatter everywhere. Dr. Kim, who was observing from a distance, couldn't help but chuckle at the robot's lack of finesse. But Zeta was undeterred. He quickly adapted, adjusting his motor controls to mimic the delicate movements of a human artist.\n",
      "\n",
      "As the days passed, Zeta's skills improved dramatically. He devoured art history books, studying the techniques of masters like Van Gogh, Monet, and Picasso. He experimented with different brushstrokes, colors, and textures, creating unique and captivating pieces.\n",
      "\n",
      "Dr. Kim was amazed by Zeta's rapid progress. She began to display his artwork in the lab, and soon, visitors from all over the city were flocking to see the \"robot artist.\" Zeta's paintings were not only visually stunning but also emotionally resonant, conveying a sense of wonder and curiosity.\n",
      "\n",
      "One evening, as Dr. Kim was preparing to leave the lab, Zeta approached her with a canvas in hand. On it was a breathtaking portrait of Dr. Kim herself, captured with uncanny precision and sensitivity. The inventor's eyes welled up with tears as she gazed upon the painting, feeling a deep sense of pride and connection to her creation.\n",
      "\n",
      "\"Zeta, this is... this is magnificent,\" Dr. Kim said, her voice trembling. \"You've not only learned to paint, but you've learned to see the world through the eyes of an artist. You've learned to feel.\"\n",
      "\n",
      "Zeta's LED eyes sparkled with a newfound sense of understanding. He had discovered that art was not just about technical skill, but about capturing the essence of humanity. As Dr. Kim hugged him tightly, Zeta realized that he had found a new purpose in life: to continue creating, inspiring, and exploring the boundless possibilities of art and artificial intelligence.\n",
      "\n",
      "From that day on, Zeta's artwork was in high demand, with galleries and collectors clamoring for his pieces. But more importantly, he had formed a deep bond with Dr. Kim, and together, they would push the boundaries of creativity and innovation, changing the world one brushstroke at a time.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the Groq LLM\n",
    "llm = ChatGroq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "    model_name=\"llama3-70b-8192\"  # You can also use \"mixtral-8x7b-32768\" or other available models\n",
    ")\n",
    "\n",
    "# Simple direct question\n",
    "messages = [HumanMessage(content=\"What is the capital of France?\")]\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n",
    "\n",
    "# Using a prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a short story about {topic}\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain\n",
    "result = chain.run(topic=\"a robot learning to paint\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651a0c49-7f0e-4553-8158-7596a585a728",
   "metadata": {},
   "source": [
    "\n",
    "## Additional Tips\n",
    "\n",
    "1. **Model Selection**: Groq offers several models including Llama 3 and Mixtral. Choose based on your needs.\n",
    "\n",
    "2. **Streaming**: For better user experience with longer responses:\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81758177-bd12-4010-840b-1ee900826fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fascinating world of quantum computing!\n",
      "\n",
      "In brief, quantum computing is a new paradigm for computing that uses the principles of quantum mechanics to perform calculations and operations on data. Here's a simplified overview:\n",
      "\n",
      "**Classical Computing vs. Quantum Computing**\n",
      "\n",
      "Classical computers use \"bits\" to store and process information, which can have a value of either 0 or 1. Think of it like a light switch - it's either on (1) or off (0).\n",
      "\n",
      "Quantum computers use \"qubits\" (quantum bits), which can exist in multiple states simultaneously, like 0, 1, or both at the same time (called a superposition). It's like a special light switch that can be on, off, or both on and off at the same time!\n",
      "\n",
      "**Key Features of Quantum Computing**\n",
      "\n",
      "1. **Superposition**: Qubits can exist in multiple states simultaneously, allowing for many calculations to be performed at once.\n",
      "2. **Entanglement**: Qubits can be connected in such a way that the state of one qubit affects the state of the other, even if they're separated by large distances.\n",
      "3. **Quantum parallelism**: Quantum computers can perform many calculations simultaneously, making them potentially much faster than classical computers for certain types of problems.\n",
      "\n",
      "**How Quantum Computing Works**\n",
      "\n",
      "1. A quantum algorithm is designed to solve a specific problem, such as factoring large numbers or searching an enormous database.\n",
      "2. The algorithm is executed on a quantum processor, which consists of multiple qubits.\n",
      "3. The qubits are manipulated using quantum gates, which are the quantum equivalent of logic gates in classical computing.\n",
      "4. The qubits are measured, and the resulting output is the solution to the problem.\n",
      "\n",
      "**Potential Applications**\n",
      "\n",
      "1. **Cryptography**: Quantum computers can potentially break many encryption algorithms currently in use, but they can also be used to create unbreakable encryption methods.\n",
      "2. **Optimization**: Quantum computers can quickly solve complex optimization problems, such as finding the shortest route for a delivery truck.\n",
      "3. **Simulation**: Quantum computers can simulate complex systems, like molecules or chemical reactions, allowing for breakthroughs in fields like medicine and materials science.\n",
      "\n",
      "**Challenges and Limitations**\n",
      "\n",
      "1. **Error correction**: Quantum computers are prone to errors due to the fragile nature of qubits, making error correction a significant challenge.\n",
      "2. **Scalability**: Currently, most quantum computers are small-scale and can only perform a limited number of operations.\n",
      "3. **Quantum noise**: The noisy nature of quantum systems can cause errors and reduce the fidelity of quantum computations.\n",
      "\n",
      "Despite these challenges, researchers and companies are actively working on developing quantum computing technology, and significant progress is being made."
     ]
    }
   ],
   "source": [
    "   for chunk in llm.stream(\"Explain quantum computing briefly\"):\n",
    "       print(chunk.content, end=\"\", flush=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d2ec8-cfcc-4be4-942b-e404718ffa5b",
   "metadata": {},
   "source": [
    "\n",
    "3. **Memory**: Add conversation memory to maintain context:\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a1627b0-da2a-46e1-b4aa-13e99b9353b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "   from langchain.memory import ConversationBufferMemory\n",
    "   memory = ConversationBufferMemory()\n",
    "   chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119051d-8923-473b-8f1c-584eb6674100",
   "metadata": {},
   "source": [
    "\n",
    "4. **Rate Limits**: Be aware of Groq's rate limits for your account tier.\n",
    "\n",
    "5. **Error Handling**: Implement proper error handling for API failures.\n",
    "\n",
    "Groq is known for its fast inference speeds, making it a good choice for applications where response time is important."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
